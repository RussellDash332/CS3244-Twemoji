{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# The basic ones\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv\n",
    "\n",
    "# Almost everything from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, mean_squared_error, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Tensorflow if needed\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# NLP packages\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, valid_data = [], [], []\n",
    "size_table = {\"train\": [], \"test\": [], \"valid\": []}\n",
    "\n",
    "for num in range(1, 13):\n",
    "    train_df = pd.read_csv(f\"https://raw.githubusercontent.com/RussellDash332/CS3244-Twemoji/main/Datasets/train_text_emoji_{num}.csv\")\n",
    "    test_df = pd.read_csv(f\"https://raw.githubusercontent.com/RussellDash332/CS3244-Twemoji/main/Datasets/test_text_emoji_{num}.csv\")\n",
    "    valid_df = pd.read_csv(f\"https://raw.githubusercontent.com/RussellDash332/CS3244-Twemoji/main/Datasets/valid_text_emoji_{num}.csv\")\n",
    "\n",
    "    train_data.append(train_df)\n",
    "    test_data.append(test_df)\n",
    "    valid_data.append(valid_df)\n",
    "\n",
    "    # print(f\"Train data size from emoji {num}:\", train_df.shape)\n",
    "    # print(f\"Test data size from emoji {num}:\", test_df.shape)\n",
    "    # print(f\"Valid data size from emoji {num}:\", valid_df.shape)\n",
    "\n",
    "    size_table[\"train\"].append(train_df.shape[0])\n",
    "    size_table[\"test\"].append(test_df.shape[0])\n",
    "    size_table[\"valid\"].append(valid_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>1846</td>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>1272</td>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>1325</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "      <td>865</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5000</td>\n",
       "      <td>824</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000</td>\n",
       "      <td>1481</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>1319</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5000</td>\n",
       "      <td>621</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>773</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5000</td>\n",
       "      <td>926</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train  test  valid\n",
       "1    5000  2000   2000\n",
       "2    5000  1846   1708\n",
       "3    5000  1272   1384\n",
       "4    5000  1325   1355\n",
       "5    5000   865    683\n",
       "6    5000   824    815\n",
       "7    5000  1481    921\n",
       "8    5000  1319   2000\n",
       "9    5000   621    713\n",
       "10   5000  2000   2000\n",
       "11   5000   773   1215\n",
       "12   5000   926    600"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_table = pd.DataFrame(size_table, index=list(range(1, 13)))\n",
    "size_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before duplicate removal:  (60000, 3) (15252, 3) (15394, 3)\n",
      "After duplicate removal:  (59907, 3) (15185, 3) (15333, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.concat(train_data)\n",
    "test_data = pd.concat(test_data)\n",
    "valid_data = pd.concat(valid_data)\n",
    "\n",
    "print(\"Before duplicate removal: \", train_data.shape, test_data.shape, valid_data.shape)\n",
    "\n",
    "train_data = train_data[~train_data.duplicated()]\n",
    "test_data = test_data[~test_data.duplicated()]\n",
    "valid_data = valid_data[~valid_data.duplicated()]\n",
    "\n",
    "print(\"After duplicate removal: \", train_data.shape, test_data.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>742489752209920004</td>\n",
       "      <td>[186, 1392]</td>\n",
       "      <td>@zaralarsson When The ticket sale start i hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>744734671477473281</td>\n",
       "      <td>[1446]</td>\n",
       "      <td>\"Friends can break your heart too\" if that ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>747884286783553537</td>\n",
       "      <td>[1392]</td>\n",
       "      <td>I'm so grateful for my girl üòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>743079873007243264</td>\n",
       "      <td>[1138]</td>\n",
       "      <td>I deserve better and ins get it.. This shit ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>743250169236357120</td>\n",
       "      <td>[763, 1381]</td>\n",
       "      <td>RT @juahoe: @rainaelise__ @_avb7 im sorry üòÇ \"w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>744834083419652096</td>\n",
       "      <td>[1620]</td>\n",
       "      <td>@jizenaaaaa well today ü§î</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>744824980626604032</td>\n",
       "      <td>[1138]</td>\n",
       "      <td>RT @DJ837: Proud of the DMV music scene right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>744214758472167424</td>\n",
       "      <td>[1447]</td>\n",
       "      <td>@marissa_greenee I think everyone knows that p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>741586067145515008</td>\n",
       "      <td>[1403]</td>\n",
       "      <td>@Olly_Medd Happy Birthday kiddo üòò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>744168852976709633</td>\n",
       "      <td>[1403]</td>\n",
       "      <td>@_hunter_noblitt thank you!!! Love you too üòò</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  annotations  \\\n",
       "2650  742489752209920004  [186, 1392]   \n",
       "3241  744734671477473281       [1446]   \n",
       "4264  747884286783553537       [1392]   \n",
       "2000  743079873007243264       [1138]   \n",
       "1659  743250169236357120  [763, 1381]   \n",
       "2938  744834083419652096       [1620]   \n",
       "2012  744824980626604032       [1138]   \n",
       "305   744214758472167424       [1447]   \n",
       "317   741586067145515008       [1403]   \n",
       "3834  744168852976709633       [1403]   \n",
       "\n",
       "                                                 tweets  \n",
       "2650  @zaralarsson When The ticket sale start i hope...  \n",
       "3241  \"Friends can break your heart too\" if that ain...  \n",
       "4264                      I'm so grateful for my girl üòç  \n",
       "2000  I deserve better and ins get it.. This shit ai...  \n",
       "1659  RT @juahoe: @rainaelise__ @_avb7 im sorry üòÇ \"w...  \n",
       "2938                           @jizenaaaaa well today ü§î  \n",
       "2012  RT @DJ837: Proud of the DMV music scene right ...  \n",
       "305   @marissa_greenee I think everyone knows that p...  \n",
       "317                   @Olly_Medd Happy Birthday kiddo üòò  \n",
       "3834       @_hunter_noblitt thank you!!! Love you too üòò  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(n=10, random_state=1010)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
