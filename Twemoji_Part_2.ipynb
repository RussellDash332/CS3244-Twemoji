{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "!pip install --disable-pip-version-check -q pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frustrated'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spellchecker = SpellChecker(language=\"en\")\n",
    "spellchecker.correction(\"frustated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT : Foobar 22/7 is pi yup!\n",
      "Foobar 22/7 is pi yup!\n",
      "forbear is pi yup\n",
      "forbear is pi yup\n",
      "ive done this before\n"
     ]
    }
   ],
   "source": [
    "# Setup preprocessor\n",
    "p.set_options(p.OPT.MENTION, p.OPT.URL, p.OPT.HASHTAG, p.OPT.EMOJI, p.OPT.SMILEY)\n",
    "print(p.clean(\"RT @test: Foobar #awesome https://www.baz.me 22/7 is pi yup!\"))\n",
    "print(p.clean(\"@test Foobar #awesome https://www.baz.me 22/7 is pi yup!\"))\n",
    "\n",
    "def clean(word):\n",
    "    if word[:2] == \"RT\":\n",
    "        word = p.clean(word[3:])[2:]\n",
    "    else:\n",
    "        word = p.clean(word)\n",
    "    word = re.sub(r\"[^\\sA-Za-z]\", \"\", word)\n",
    "    # return re.sub(r\"\\s+\", \" \", word)\n",
    "    return \" \".join(map(spellchecker.correction, re.sub(r\"\\s+\", \" \", word).lower().split()))\n",
    "\n",
    "# Foobar becomes forbear, spellchecker autoconverts to lowercase\n",
    "print(clean(\"RT @test: Foobar #awesome https://www.baz.me 22/7 is pi yup!\"))\n",
    "print(clean(\"@test Foobar #awesome https://www.baz.me 22/7 is pi yup!\"))\n",
    "\n",
    "# For apostrophes, we decided to combine the abbreviated words\n",
    "print(clean(\"I've done this  before @@xoxo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, valid_data = [], [], []\n",
    "size_table = {\"train\": [], \"test\": [], \"valid\": []}\n",
    "\n",
    "emoji_map = pd.read_csv(os.getcwd() + \"\\Datasets\\Original\\emoji_map_1791.csv\")\n",
    "emoji_idx = [1381, 1424, 1392, 1447, 186, 1389, 1420, 1620, 1403, 763, 1138, 1446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['üòÇ', 'üò≠', 'üòç', 'üôÑ', '‚ù§', 'üòä', 'üò©', 'ü§î', 'üòò', 'üèΩ', 'üíØ', 'üôÉ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_list = list(map(lambda x: emoji_map.iloc[x, 0], emoji_idx))\n",
    "emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèΩ\n"
     ]
    }
   ],
   "source": [
    "# This particular emoji has a different behaviour\n",
    "print(emoji_map.iloc[emoji_idx[-3], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(1, 13):\n",
    "    train_df = pd.read_csv(f\"https://raw.githubusercontent.com/RussellDash332/CS3244-Twemoji/main/Datasets/train_text_emoji_{num}.csv\")\n",
    "    test_df = pd.read_csv(f\"https://raw.githubusercontent.com/RussellDash332/CS3244-Twemoji/main/Datasets/test_text_emoji_{num}.csv\")\n",
    "    valid_df = pd.read_csv(f\"https://raw.githubusercontent.com/RussellDash332/CS3244-Twemoji/main/Datasets/valid_text_emoji_{num}.csv\")\n",
    "\n",
    "    def list_to_emoji(string):\n",
    "        emojis = list(map(int, string[1:-1].split(\",\")))\n",
    "        return str().join(map(lambda x: emoji_map.iloc[x, 0], emojis))\n",
    "\n",
    "    def emoji_to_index(emoji):\n",
    "        return emoji_list.index(emoji)\n",
    "\n",
    "    # Convert \"[1381, 1424]\" to \"üòÇüò≠\"\n",
    "    train_df[\"annotations\"] = train_df[\"annotations\"].apply(list_to_emoji)\n",
    "    test_df[\"annotations\"] = test_df[\"annotations\"].apply(list_to_emoji)\n",
    "    valid_df[\"annotations\"] = valid_df[\"annotations\"].apply(list_to_emoji)\n",
    "\n",
    "    # Update: drop the rows with multiple emojis and keep the single-labelled ones\n",
    "    train_df = train_df[train_df.annotations == emoji_list[num-1]]\n",
    "    test_df = test_df[test_df.annotations == emoji_list[num-1]]\n",
    "    valid_df = valid_df[valid_df.annotations == emoji_list[num-1]]\n",
    "    \n",
    "    # Convert \"üòÇ\" to 0\n",
    "    train_df[\"labels\"] = train_df[\"annotations\"].apply(emoji_to_index)\n",
    "    test_df[\"labels\"] = test_df[\"annotations\"].apply(emoji_to_index)\n",
    "    valid_df[\"labels\"] = valid_df[\"annotations\"].apply(emoji_to_index)\n",
    "\n",
    "    # Apply cleaning from twitter-preprocessor\n",
    "    train_df[\"tweets\"] = train_df[\"tweets\"].apply(clean)\n",
    "    test_df[\"tweets\"] = test_df[\"tweets\"].apply(clean)\n",
    "    valid_df[\"tweets\"] = valid_df[\"tweets\"].apply(clean)\n",
    "\n",
    "    train_data.append(train_df)\n",
    "    test_data.append(test_df)\n",
    "    valid_data.append(valid_df)\n",
    "\n",
    "    # print(f\"Train data size from emoji {num}:\", train_df.shape)\n",
    "    # print(f\"Test data size from emoji {num}:\", test_df.shape)\n",
    "    # print(f\"Valid data size from emoji {num}:\", valid_df.shape)\n",
    "\n",
    "    size_table[\"train\"].append(train_df.shape[0])\n",
    "    size_table[\"test\"].append(test_df.shape[0])\n",
    "    size_table[\"valid\"].append(valid_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>valid</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4504</td>\n",
       "      <td>1804</td>\n",
       "      <td>1782</td>\n",
       "      <td>8090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4240</td>\n",
       "      <td>1570</td>\n",
       "      <td>1429</td>\n",
       "      <td>7239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4324</td>\n",
       "      <td>1093</td>\n",
       "      <td>1172</td>\n",
       "      <td>6589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4609</td>\n",
       "      <td>1215</td>\n",
       "      <td>1228</td>\n",
       "      <td>7052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4232</td>\n",
       "      <td>731</td>\n",
       "      <td>556</td>\n",
       "      <td>5519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4567</td>\n",
       "      <td>743</td>\n",
       "      <td>749</td>\n",
       "      <td>6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4345</td>\n",
       "      <td>1308</td>\n",
       "      <td>807</td>\n",
       "      <td>6460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4557</td>\n",
       "      <td>1216</td>\n",
       "      <td>1840</td>\n",
       "      <td>7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4086</td>\n",
       "      <td>512</td>\n",
       "      <td>591</td>\n",
       "      <td>5189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4289</td>\n",
       "      <td>1724</td>\n",
       "      <td>1715</td>\n",
       "      <td>7728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4380</td>\n",
       "      <td>690</td>\n",
       "      <td>1037</td>\n",
       "      <td>6107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4755</td>\n",
       "      <td>880</td>\n",
       "      <td>575</td>\n",
       "      <td>6210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train  test  valid   sum\n",
       "1    4504  1804   1782  8090\n",
       "2    4240  1570   1429  7239\n",
       "3    4324  1093   1172  6589\n",
       "4    4609  1215   1228  7052\n",
       "5    4232   731    556  5519\n",
       "6    4567   743    749  6059\n",
       "7    4345  1308    807  6460\n",
       "8    4557  1216   1840  7613\n",
       "9    4086   512    591  5189\n",
       "10   4289  1724   1715  7728\n",
       "11   4380   690   1037  6107\n",
       "12   4755   880    575  6210"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_table = pd.DataFrame(size_table, index=list(range(1, 13)))\n",
    "size_table[\"sum\"] = size_table.train + size_table.test + size_table.valid\n",
    "size_table\n",
    "\n",
    "# training is balanced, good to go\n",
    "# stick with this t-t-v combination\n",
    "# this was before duplicate removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    52888\n",
       "test     13486\n",
       "valid    13481\n",
       "sum      79855\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_table.apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>743419925738496000</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>school is so dead o my god</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>742411940677492736</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>lol ive been told mine is worse than yours but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>744394777974628352</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>im excited to hear them that shit is going rat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>743679858199298049</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>damn alicia knows everything even indirect tweets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>742579985588887552</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>that sound like everything</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>744391978171904000</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>always</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>747994577357930497</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>had to flex on tia people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>746430898464161792</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>do eco is really the coolest do</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>742758236986576897</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>we be so jobless</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>744574211226767360</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>stu if they played both roles then they deserv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4504 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id annotations  \\\n",
       "0     743419925738496000           üòÇ   \n",
       "1     742411940677492736           üòÇ   \n",
       "2     744394777974628352           üòÇ   \n",
       "3     743679858199298049           üòÇ   \n",
       "4     742579985588887552           üòÇ   \n",
       "...                  ...         ...   \n",
       "4995  744391978171904000           üòÇ   \n",
       "4996  747994577357930497           üòÇ   \n",
       "4997  746430898464161792           üòÇ   \n",
       "4998  742758236986576897           üòÇ   \n",
       "4999  744574211226767360           üòÇ   \n",
       "\n",
       "                                                 tweets  labels  \n",
       "0                            school is so dead o my god       0  \n",
       "1     lol ive been told mine is worse than yours but...       0  \n",
       "2     im excited to hear them that shit is going rat...       0  \n",
       "3     damn alicia knows everything even indirect tweets       0  \n",
       "4                            that sound like everything       0  \n",
       "...                                                 ...     ...  \n",
       "4995                                             always       0  \n",
       "4996                          had to flex on tia people       0  \n",
       "4997                    do eco is really the coolest do       0  \n",
       "4998                                   we be so jobless       0  \n",
       "4999  stu if they played both roles then they deserv...       0  \n",
       "\n",
       "[4504 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before missing and duplicate removal:  (52888, 4) (13486, 4) (13481, 4)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.concat(train_data)\n",
    "test_data = pd.concat(test_data)\n",
    "valid_data = pd.concat(valid_data)\n",
    "\n",
    "print(\"Before missing and duplicate removal: \", train_data.shape, test_data.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After missing and duplicate removal:  (52884, 4) (13485, 4) (13481, 4)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data[~train_data.duplicated()]\n",
    "train_data = train_data [train_data.tweets != \"\"]\n",
    "\n",
    "test_data = test_data[~test_data.duplicated()]\n",
    "test_data = test_data[test_data.tweets != \"\"]\n",
    "\n",
    "valid_data = valid_data[~valid_data.duplicated()]\n",
    "valid_data = valid_data[valid_data.tweets != \"\"]\n",
    "\n",
    "print(\"After missing and duplicate removal: \", train_data.shape, test_data.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(\"id\", axis=1)\n",
    "test_data = test_data.drop(\"id\", axis=1)\n",
    "valid_data = valid_data.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>üòç</td>\n",
       "      <td>i appreciate all you little booty women in thi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>üò©</td>\n",
       "      <td>currently having a music shoot on snapchat lol</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>‚ù§</td>\n",
       "      <td>miss you guys so much man</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>üíØ</td>\n",
       "      <td>just received his first box hit him up for an ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>üíØ</td>\n",
       "      <td>i keep telling you nights</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>üò©</td>\n",
       "      <td>some jamba juice sounds sooo good right now</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>‚ù§</td>\n",
       "      <td>my heart</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>üôÉ</td>\n",
       "      <td>tired all day but wide awake at night</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>ü§î</td>\n",
       "      <td>i gotta question</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>üíØ</td>\n",
       "      <td>whether you doing good or bad somebody is goin...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotations                                             tweets  labels\n",
       "759            üòç  i appreciate all you little booty women in thi...       2\n",
       "3861           üò©     currently having a music shoot on snapchat lol       6\n",
       "794            ‚ù§                          miss you guys so much man       4\n",
       "1555           üíØ  just received his first box hit him up for an ...      10\n",
       "3497           üíØ                          i keep telling you nights      10\n",
       "651            üò©        some jamba juice sounds sooo good right now       6\n",
       "15             ‚ù§                                           my heart       4\n",
       "1261           üôÉ              tired all day but wide awake at night      11\n",
       "3486           ü§î                                   i gotta question       7\n",
       "2249           üíØ  whether you doing good or bad somebody is goin...      10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(n=10, random_state=1010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(os.getcwd() + \"\\Datasets\\\\train_text_emoji_clean.csv\", index=False)\n",
    "test_data.to_csv(os.getcwd() + \"\\Datasets\\\\test_text_emoji_clean.csv\", index=False)\n",
    "valid_data.to_csv(os.getcwd() + \"\\Datasets\\\\valid_text_emoji_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XLNet -> sentiment analysis / Text Classification (https://www.topbots.com/leading-nlp-language-models-2020/#language-models-2020-3)\n",
    "- OpenAI‚Äôs GPT2 -> supervised learning on task-specific datasets (https://insights.daffodilsw.com/blog/top-5-nlp-language-models)\n",
    "- Embedding Layers (https://machinelearningmastery.com/what-are-word-embeddings/)\n",
    "- Word2Vec (https://machinelearningmastery.com/what-are-word-embeddings/)\\\n",
    "- GloVe (https://machinelearningmastery.com/what-are-word-embeddings/)\n",
    "- Parsing (https://www.analyticsvidhya.com/blog/2020/12/understanding-text-classification-in-nlp-with-movie-review-example-example/#h2_6)\n",
    "- Semantic (https://www.analyticsvidhya.com/blog/2020/12/understanding-text-classification-in-nlp-with-movie-review-example-example/#h2_7)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
